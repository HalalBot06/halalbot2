#!/usr/bin/env python3
"""
HalalBot Database Connection Test for Railway PostgreSQL Migration
Tests database connectivity, data integrity, and system readiness
"""

import os
import sys
import json
import psycopg2
from psycopg2.extras import RealDictCursor
import numpy as np
from pathlib import Path

def test_sentence_transformers():
    """Test if sentence-transformers model loads correctly"""
    print("ü§ñ Testing sentence-transformers model...")
    
    try:
        from sentence_transformers import SentenceTransformer
        model = SentenceTransformer('all-MiniLM-L6-v2')
        print("‚úÖ Sentence transformer model loaded successfully")
        
        # Test encoding
        test_text = "This is a test sentence for Islamic knowledge"
        test_embedding = model.encode([test_text])
        expected_dims = 384  # all-MiniLM-L6-v2 produces 384-dimensional embeddings
        
        if test_embedding.shape == (1, expected_dims):
            print(f"‚úÖ Test embedding generated: shape {test_embedding.shape}")
            return True, model
        else:
            print(f"‚ùå Unexpected embedding dimensions: {test_embedding.shape}, expected (1, {expected_dims})")
            return False, None
            
    except ImportError as e:
        print(f"‚ùå Failed to import sentence-transformers: {e}")
        print("üí° Install with: pip install sentence-transformers")
        return False, None
    except Exception as e:
        print(f"‚ùå Model loading failed: {e}")
        return False, None

def test_database_connection():
    """Test basic database connectivity"""
    print("üîó Testing database connection...")
    
    database_url = os.getenv('DATABASE_URL')
    if not database_url:
        print("‚ùå DATABASE_URL environment variable not set")
        print("üí° Set it with your Railway database URL:")
        print("   export DATABASE_URL='postgresql://user:pass@host:port/dbname'")
        return False, None
    
    print("‚úÖ DATABASE_URL is configured")
    
    try:
        # Test connection
        conn = psycopg2.connect(database_url)
        print("‚úÖ Successfully connected to PostgreSQL database")
        
        # Test basic query
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            cursor.execute("SELECT version();")
            version_info = cursor.fetchone()
            print(f"‚úÖ PostgreSQL version: {version_info['version']}")
        
        return True, conn
        
    except psycopg2.Error as e:
        print(f"‚ùå Database connection failed: {e}")
        return False, None
    except Exception as e:
        print(f"‚ùå Unexpected error connecting to database: {e}")
        return False, None

def test_pgvector_extension(conn):
    """Check if pgvector extension is available (optional)"""
    print("üß¨ Checking for pgvector extension...")
    
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            cursor.execute("SELECT * FROM pg_extension WHERE extname = 'vector';")
            result = cursor.fetchone()
            
            if result:
                print("‚úÖ pgvector extension is installed")
                return True
            else:
                print("‚ÑπÔ∏è  pgvector extension not found - using JSONB embeddings instead")
                return False
                
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not check pgvector extension: {e}")
        return False

def test_table_structure(conn):
    """Verify required tables and their structure exist"""
    print("üèóÔ∏è  Testing table structure...")
    
    required_tables = {
        'users': ['id', 'email', 'password_hash', 'is_admin', 'invite_code'],
        'invite_codes': ['code', 'used', 'used_by_email', 'created_at'],
        'documents': ['id', 'doc_id', 'text', 'source', 'category', 'embedding_json', 'metadata'],
        'search_queries': ['id', 'user_id', 'query', 'results_count', 'timestamp'],
        'feedback': ['id', 'user_id', 'document_id', 'query', 'feedback_type']
    }
    
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            # Check which tables exist
            cursor.execute("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
                ORDER BY table_name;
            """)
            existing_tables = [row['table_name'] for row in cursor.fetchall()]
            
            print(f"üìã Found tables: {', '.join(existing_tables)}")
            
            missing_tables = []
            for table_name in required_tables.keys():
                if table_name not in existing_tables:
                    missing_tables.append(table_name)
                else:
                    print(f"‚úÖ Table '{table_name}' exists")
            
            if missing_tables:
                print(f"‚ùå Missing tables: {', '.join(missing_tables)}")
                return False
            
            # Check documents table structure in detail
            cursor.execute("""
                SELECT column_name, data_type, is_nullable
                FROM information_schema.columns 
                WHERE table_name = 'documents'
                ORDER BY ordinal_position;
            """)
            
            columns = cursor.fetchall()
            print("üìä Documents table structure:")
            for col in columns:
                nullable = "NULL" if col['is_nullable'] == 'YES' else "NOT NULL"
                print(f"   ‚Ä¢ {col['column_name']}: {col['data_type']} ({nullable})")
            
            return True
            
    except Exception as e:
        print(f"‚ùå Table structure test failed: {e}")
        return False

def test_document_data_integrity(conn):
    """Test document data and embedding integrity"""
    print("üìä Testing document data integrity...")
    
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            # Get total document count
            cursor.execute("SELECT COUNT(*) as total FROM documents;")
            total_docs = cursor.fetchone()['total']
            print(f"üìÑ Total documents: {total_docs:,}")
            
            if total_docs == 0:
                print("‚ö†Ô∏è  No documents found in database")
                return False
            
            # Check documents by category
            cursor.execute("""
                SELECT category, COUNT(*) as count 
                FROM documents 
                GROUP BY category 
                ORDER BY count DESC;
            """)
            
            categories = cursor.fetchall()
            print("üìö Documents by category:")
            for cat in categories:
                print(f"   ‚Ä¢ {cat['category']}: {cat['count']:,} documents")
            
            # Check for missing text content
            cursor.execute("SELECT COUNT(*) as count FROM documents WHERE text IS NULL OR text = '';")
            missing_text = cursor.fetchone()['count']
            if missing_text > 0:
                print(f"‚ö†Ô∏è  {missing_text} documents have missing text content")
            else:
                print("‚úÖ All documents have text content")
            
            # Check embedding integrity
            cursor.execute("SELECT COUNT(*) as count FROM documents WHERE embedding_json IS NULL;")
            missing_embeddings = cursor.fetchone()['count']
            
            if missing_embeddings > 0:
                print(f"‚ùå {missing_embeddings} documents missing embeddings")
                return False
            else:
                print("‚úÖ All documents have embeddings")
            
            # Test a few random embeddings for structure
            cursor.execute("""
                SELECT embedding_json 
                FROM documents 
                WHERE embedding_json IS NOT NULL 
                LIMIT 5;
            """)
            
            sample_embeddings = cursor.fetchall()
            embedding_dims = []
            
            for i, row in enumerate(sample_embeddings):
                try:
                    embedding = row['embedding_json']
                    if isinstance(embedding, list):
                        dims = len(embedding)
                        embedding_dims.append(dims)
                        if i == 0:  # Only print first one
                            print(f"‚úÖ Sample embedding dimensions: {dims}")
                    else:
                        print(f"‚ùå Embedding {i+1} is not a list: {type(embedding)}")
                        return False
                except Exception as e:
                    print(f"‚ùå Error checking embedding {i+1}: {e}")
                    return False
            
            # Verify all embeddings have same dimensions
            if len(set(embedding_dims)) == 1:
                expected_dims = 384  # all-MiniLM-L6-v2
                actual_dims = embedding_dims[0]
                if actual_dims == expected_dims:
                    print(f"‚úÖ All embeddings have correct dimensions: {actual_dims}")
                else:
                    print(f"‚ö†Ô∏è  Unexpected embedding dimensions: {actual_dims}, expected {expected_dims}")
            else:
                print(f"‚ùå Inconsistent embedding dimensions: {set(embedding_dims)}")
                return False
            
            return True
            
    except Exception as e:
        print(f"‚ùå Data integrity test failed: {e}")
        return False

def test_sample_queries(conn, model):
    """Test sample search functionality"""
    print("üîç Testing sample queries...")
    
    if not model:
        print("‚ö†Ô∏è  Skipping query test - model not available")
        return True
    
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            # Test query
            test_query = "What does Islam say about prayer?"
            query_embedding = model.encode([test_query])[0].tolist()
            
            print(f"üîç Testing query: '{test_query}'")
            
            # Simple similarity search using JSONB
            # Note: This is a basic implementation - in production you'd want more efficient similarity search
            cursor.execute("""
                SELECT id, doc_id, text, source, category, title,
                       SUBSTRING(text FROM 1 FOR 100) as text_preview
                FROM documents 
                WHERE text IS NOT NULL 
                AND LENGTH(text) > 50
                LIMIT 10;
            """)
            
            sample_results = cursor.fetchall()
            
            if sample_results:
                print(f"‚úÖ Found {len(sample_results)} sample documents for testing")
                print("üìÑ Sample results:")
                for i, result in enumerate(sample_results[:3]):
                    source_display = result['source'] or 'Unknown'
                    print(f"   {i+1}. [{result['category']}] {result['text_preview']}...")
                    print(f"      Source: {source_display}")
                return True
            else:
                print("‚ùå No documents found for sample query")
                return False
                
    except Exception as e:
        print(f"‚ùå Sample query test failed: {e}")
        return False

def test_search_service_integration():
    """Test the search service integration"""
    print("üîß Testing search service integration...")
    
    try:
        # Try to import the search service
        sys.path.append('.')
        from services.search_service import DatabaseSearchService
        
        service = DatabaseSearchService()
        print("‚úÖ Search service imported successfully")
        
        # Test a simple search
        results = service.search("prayer", top_k=3, min_score=0.3)
        
        if results:
            print(f"‚úÖ Search service returned {len(results)} results")
            for i, result in enumerate(results[:2]):
                print(f"   {i+1}. Score: {result['score']:.3f} | Category: {result['category']}")
            return True
        else:
            print("‚ö†Ô∏è  Search service returned no results")
            return True  # This might be normal depending on data
            
    except ImportError:
        print("‚ÑπÔ∏è  Search service not found - this is normal if not yet implemented")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è  Search service test failed: {e}")
        return True  # Not critical for basic connection test

def check_environment():
    """Check environment and dependencies"""
    print("üåç Checking environment...")
    
    # Check Python version
    python_version = sys.version.split()[0]
    print(f"üêç Python version: {python_version}")
    
    # Check required packages
    required_packages = [
        'psycopg2',
        'sentence_transformers', 
        'numpy',
        'streamlit'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package.replace('-', '_'))
            print(f"‚úÖ {package} is installed")
        except ImportError:
            missing_packages.append(package)
            print(f"‚ùå {package} is missing")
    
    if missing_packages:
        print(f"\nüí° Install missing packages with:")
        print(f"   pip install {' '.join(missing_packages)}")
        return False
    
    return True

def main():
    """Run all connection tests"""
    print("üöÄ HalalBot Database Connection Test for Railway PostgreSQL")
    print("=" * 60)
    
    all_tests_passed = True
    
    # Test environment
    print("\n1. Environment Check:")
    if not check_environment():
        all_tests_passed = False
    
    # Test sentence transformers
    print("\n2. Model Loading Test:")
    model_success, model = test_sentence_transformers()
    if not model_success:
        all_tests_passed = False
    
    # Test database connection
    print("\n3. Database Connection Test:")
    db_success, conn = test_database_connection()
    if not db_success:
        all_tests_passed = False
        print("\nüí• Cannot proceed without database connection")
        return
    
    try:
        # Test pgvector extension
        print("\n4. Extension Check:")
        test_pgvector_extension(conn)
        
        # Test table structure
        print("\n5. Table Structure Test:")
        if not test_table_structure(conn):
            all_tests_passed = False
        
        # Test data integrity
        print("\n6. Data Integrity Test:")
        if not test_document_data_integrity(conn):
            all_tests_passed = False
        
        # Test sample queries
        print("\n7. Sample Query Test:")
        if not test_sample_queries(conn, model):
            all_tests_passed = False
        
        # Test search service
        print("\n8. Search Service Integration Test:")
        test_search_service_integration()  # Non-critical
        
    finally:
        if conn:
            conn.close()
            print("\nüîå Database connection closed")
    
    # Final results
    print("\n" + "=" * 60)
    if all_tests_passed:
        print("üéâ ALL TESTS PASSED! HalalBot database is ready for deployment.")
        print("\n‚úÖ Next steps:")
        print("   ‚Ä¢ Deploy your Streamlit app to Railway")
        print("   ‚Ä¢ Test the full application with real queries")
        print("   ‚Ä¢ Monitor performance and query logs")
        print("   ‚Ä¢ Set up backup procedures")
    else:
        print("‚ö†Ô∏è  SOME TESTS FAILED! Please review the issues above.")
        print("\nüîß Common fixes:")
        print("   ‚Ä¢ Ensure DATABASE_URL is correctly set")
        print("   ‚Ä¢ Run database migration script if tables are missing")
        print("   ‚Ä¢ Check that embeddings were properly migrated")
        print("   ‚Ä¢ Install missing Python packages")
    
    return all_tests_passed

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  Test interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nüí• Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)